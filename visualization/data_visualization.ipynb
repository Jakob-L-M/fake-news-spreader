{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/reddit_corpus_balanced_filtered.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary for theme groups\n",
    "theme_groups = {}\n",
    "theme_groups['SARS-CoV-2'] = ['r/CovidVaccinated', 'r/Masks4All', 'r/NoLockdownsNoMasks', 'r/EndTheLockdowns', 'r/COVID19', 'r/COVID19positive', 'r/CoronavirusCanada', 'r/CoronavirusRecession', 'r/CoronavirusUK', 'r/CoronavirusUS', 'r/Coronavirus', 'r/LockdownSkepticism']\n",
    "theme_groups['Vaccines'] = ['r/CovidVaccinated', 'r/VACCINES', 'r/vaxxhappened', 'r/AntiVaxxers', 'r/antivax', 'r/TrueAntiVaccination', 'r/DebateVaccine', 'r/DebateVaccines']\n",
    "theme_groups['Abortion'] = ['r/AskProchoice', 'r/prochoice', 'r/insaneprolife', 'r/prolife', 'r/ProLifeLibertarians', 'r/Abortiondebate', 'r/abortion']\n",
    "theme_groups['womens-and-mens-rights'] = ['r/Feminism', 'r/feminisms', 'r/RadicalFeminism', 'r/RadicalFeminismUSA', 'r/MRActivism', 'r/MensRights', 'r/antifeminists', 'r/feminismformen', 'r/masculism', 'r/GenderCritical', 'r/Egalitarianism']\n",
    "theme_groups['Gun-control'] = ['r/Firearms', 'r/GunsAreCool', 'r/liberalgunowners', 'r/progun', 'r/guncontrol', 'r/GunDebates', 'r/GunResearch', 'r/gunpolitics']\n",
    "theme_groups['Climate-change'] = ['r/climateskeptics', 'r/GlobalClimateChange', 'r/climate', 'r/climatechange']\n",
    "theme_groups['5G'] = ['r/5GDebate']\n",
    "theme_groups['general-political-debate'] = ['r/JoeBiden', 'r/LeftistsForMen', 'r/Liberal', 'r/LockdownCriticalLeft', 'r/democrats', 'r/Conservative', 'r/ConservativesOnly', 'r/conservatives', 'r/Republican', 'r/RepublicanValues', 'r/politics', 'r/uspolitics']\n",
    "\n",
    "bias = {}\n",
    "bias['pro'] = ['r/CovidVaccinated', 'r/Masks4All', 'r/CovidVaccinated', 'r/VACCINES', 'r/vaxxhappened', 'r/AskProchoice', 'r/prochoice', 'r/insaneprolife', 'r/Firearms', 'r/GunsAreCool',  'r/liberalgunowners',  'r/progun']\n",
    "bias['anit'] = ['r/NoLockdownsNoMasks', 'r/EndTheLockdowns', 'r/AntiVaxxers',  'r/antivax',  'r/TrueAntiVaccination', 'r/prolife', 'r/ProLifeLibertarians', 'r/guncontrol']\n",
    "bias['unbiased'] = ['r/COVID19', 'r/COVID19positive', 'r/CoronavirusCanada','r/CoronavirusRecession','r/CoronavirusUK','r/CoronavirusUS','r/Coronavirus','r/LockdownSkepticism','r/DebateVaccine','r/DebateVaccines','r/Abortiondebate','r/abortion', 'r/GunDebates','r/GunResearch','r/gunpolitics']\n",
    "\n",
    "# !ProLifeLibertarians is missing any labled data\n",
    "\n",
    "#theme_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data end sort to dictionaries for later plots\n",
    "sub_reddit_dic = {}\n",
    "\n",
    "for row in df.iterrows():\n",
    "    data = row[1]\n",
    "    documents = data['documents']\n",
    "    \n",
    "    for doc_id, text, date, sub_reddit, labels in documents:\n",
    "        if len(labels) > 0:\n",
    "            #print(labels)\n",
    "            if sub_reddit not in sub_reddit_dic:\n",
    "                sub_reddit_dic[sub_reddit] = {'politics': {'count':0,'LEFT_CENTER':0,'LEFT':0,'LEAST_BIASED':0,'RIGHT_CENTER':0,'SATIRE':0,'PRO_SCIENCE':0,'RIGHT':0,'EXTREME_LEFT':0,'CONSPIRACY_PSEUDOSCIENCE':0,'EXTREME_RIGHT':0,'PRO_RUSSIAN_PROPAGANDA':0}, 'news': {'count':0,'HIGH':0,'VERY_HIGH':0,'MOSTLY_FACTUAL':0,'MIXED':0,'VERY_LOW':0,'LOW':0}}\n",
    "            for label in labels:\n",
    "                pol_bias = label[2][0]\n",
    "                news_bias = label[3]\n",
    "                if len(pol_bias) > 0:\n",
    "                    sub_reddit_dic[sub_reddit]['politics'][pol_bias] += 1\n",
    "                    sub_reddit_dic[sub_reddit]['politics']['count'] += 1\n",
    "                if (len(news_bias) > 0):\n",
    "                    sub_reddit_dic[sub_reddit]['news'][news_bias] += 1\n",
    "                    sub_reddit_dic[sub_reddit]['news']['count'] += 1\n",
    "                    \n",
    "theme_dic = {}\n",
    "\n",
    "for theme in theme_groups:\n",
    "    theme_dic[theme] = {'politics': {'count':0,'LEFT_CENTER':0,'LEFT':0,'LEAST_BIASED':0,'RIGHT_CENTER':0,'SATIRE':0,'PRO_SCIENCE':0,'RIGHT':0,'EXTREME_LEFT':0,'CONSPIRACY_PSEUDOSCIENCE':0,'EXTREME_RIGHT':0,'PRO_RUSSIAN_PROPAGANDA':0}, 'news': {'count':0,'HIGH':0,'VERY_HIGH':0,'MOSTLY_FACTUAL':0,'MIXED':0,'VERY_LOW':0,'LOW':0}}\n",
    "    for sub_reddit in theme_groups[theme]:\n",
    "        if sub_reddit not in sub_reddit_dic:\n",
    "            continue\n",
    "        for i in sub_reddit_dic[sub_reddit]['politics']:\n",
    "            theme_dic[theme]['politics'][i] += sub_reddit_dic[sub_reddit]['politics'][i]\n",
    "        for i in sub_reddit_dic[sub_reddit]['news']:\n",
    "            theme_dic[theme]['news'][i] += sub_reddit_dic[sub_reddit]['news'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df # Free up some RAM\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of news distribution in categories. Singel Plot\n",
    "plt.figure(figsize=(16,8))\n",
    "cmap = ['orangered', 'lime', 'aqua', 'violet', 'gold', 'grey', 'blue', 'darkmagenta']\n",
    "categories = ['VERY_HIGH','HIGH','MOSTLY_FACTUAL','MIXED','LOW','VERY_LOW']\n",
    "width = 1/len(theme_dic)\n",
    "max_y = 0\n",
    "for ind, theme in enumerate(theme_dic):\n",
    "    data = theme_dic[theme]['news']\n",
    "    n = data['count']\n",
    "    heights = [data[i]/n if i in data else 0 for i in categories]\n",
    "    if(max(heights) > max_y):\n",
    "            max_y = max(heights)\n",
    "    plt.bar(x = [i*3+ind*(1.5*width)-(1.5*width*(len(theme_dic)-1)/2) for i in range(len(categories))], height=heights, width=width, color=cmap[ind])\n",
    "plt.xticks([i*3 for i in range(len(categories))],categories)\n",
    "plt.legend(theme_dic)\n",
    "plt.ylabel(\"relative percentage\")\n",
    "plt.yticks([i/10 for i in range(min(11,int(max_y*10) + 2))], [str(i*10)+'%' for i in range(min(11,int(max_y*10) + 2))])\n",
    "plt.title(\"News bias in all groups\")\n",
    "plt.savefig(\"./overview/news.pdf\")\n",
    "plt.show()\n",
    "\n",
    "# Plot of political distribution in categories. Singel Plot\n",
    "plt.figure(figsize=(16,8))\n",
    "cmap = ['orangered', 'lime', 'aqua', 'violet', 'gold', 'grey', 'blue', 'darkmagenta']\n",
    "categories = ['EXTREME_LEFT','LEFT','LEFT_CENTER','LEAST_BIASED','RIGHT_CENTER','RIGHT','EXTREME_RIGHT','CONSPIRACY_PSEUDOSCIENCE','PRO_RUSSIAN_PROPAGANDA', 'PRO_SCIENCE']\n",
    "max_y = 0\n",
    "for ind, theme in enumerate(theme_dic):\n",
    "    data = theme_dic[theme]['politics']\n",
    "    n = data['count']\n",
    "    heights = [data[i]/n if i in data else 0 for i in categories]\n",
    "    if(max(heights) > max_y):\n",
    "            max_y = max(heights)\n",
    "    plt.bar(x = [i*3+ind*(1.5*width)-(1.5*width*(len(theme_dic)-1)/2) for i in range(len(categories))], height=heights, width=width, color=cmap[ind])\n",
    "plt.xticks([i*3 for i in range(len(categories))],[j if ind % 2 == 0 else \" \\n\"+j for ind,j in enumerate(categories)])\n",
    "plt.legend(theme_dic)\n",
    "plt.ylabel(\"relative percentage\")\n",
    "plt.yticks([i/10 for i in range(min(11,int(max_y*10) + 2))], [str(i*10)+'%' for i in range(min(11,int(max_y*10) + 2))])\n",
    "plt.title(\"Political bias in all groups\")\n",
    "plt.savefig(\"./overview/political.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each subreddit of a category\n",
    "\n",
    "# custom colormap. len = 12, since the biggest category consists out of 12 sub-reddits\n",
    "cmap = ['orangered', 'darkmagenta', 'aqua', 'violet', 'gold', 'grey', 'blue', 'lime', 'steelblue', 'silver', 'deeppink', 'olivedrab']\n",
    "\n",
    "# POLITICAL BIAS\n",
    "# Ignore certian categories\n",
    "categories = ['EXTREME_LEFT','LEFT','LEFT_CENTER','LEAST_BIASED','RIGHT_CENTER','RIGHT','EXTREME_RIGHT']#,'CONSPIRACY_PSEUDOSCIENCE','PRO_RUSSIAN_PROPAGANDA','PRO_SCIENCE']\n",
    "for group in theme_groups:\n",
    "    plt.figure(figsize=(16,8))\n",
    "    max_y = 0\n",
    "    \n",
    "    sub_reddits_in_group = [i for i in theme_groups[group] if i in sub_reddit_dic]\n",
    "    for ind, sub_reddit in enumerate(sub_reddits_in_group):\n",
    "        \n",
    "        data = sub_reddit_dic[sub_reddit]['politics']\n",
    "        # normalization\n",
    "        n = data['count'] - data['CONSPIRACY_PSEUDOSCIENCE'] - data['PRO_RUSSIAN_PROPAGANDA'] - data['PRO_SCIENCE']\n",
    "        \n",
    "        width = 1/len(sub_reddits_in_group)\n",
    "        heights = [data[i]/n if i in data else 0 for i in categories]\n",
    "        \n",
    "        # max hight for y-axis labels\n",
    "        if(max(heights) > max_y):\n",
    "            max_y = max(heights)\n",
    "        \n",
    "        plt.bar(x = [i*3+ind*(1.5*width)-(1.5*width*(len(sub_reddits_in_group)-1)/2) for i in range(len(categories))], height=heights, width=width, color=cmap[ind])\n",
    "    plt.xticks([i*3 for i in range(len(categories))],[j.replace('_', ' ') for j in categories])\n",
    "    plt.legend(sub_reddits_in_group)\n",
    "    plt.title('Political tendencies for sub-reddits in group: ' + group, fontsize=20)\n",
    "    plt.ylabel('relative percentage', fontsize=16)\n",
    "    plt.yticks([i/10 for i in range(min(11,int(max_y*10) + 2))], [str(i*10)+'%' for i in range(min(11,int(max_y*10) + 2))])\n",
    "    plt.savefig('./categories/' + group + '_politics.pdf')\n",
    "    plt.show()\n",
    "\n",
    "# FACTUAL STRUCTURE\n",
    "categories = ['VERY_HIGH','HIGH','MOSTLY_FACTUAL','MIXED','LOW','VERY_LOW']\n",
    "for group in theme_groups:\n",
    "    plt.figure(figsize=(16,8))\n",
    "    max_y = 0\n",
    "    # Dont iterate over sub-reddits with no labeled data\n",
    "    sub_reddits_in_group = [i for i in theme_groups[group] if i in sub_reddit_dic]\n",
    "    for ind, sub_reddit in enumerate(sub_reddits_in_group):\n",
    "        if (sub_reddit not in sub_reddit_dic):\n",
    "            continue\n",
    "        data = sub_reddit_dic[sub_reddit]['news']\n",
    "        n = data['count']\n",
    "        width = 1/len(sub_reddits_in_group)\n",
    "        heights = [data[i]/n if i in data else 0 for i in categories]\n",
    "        if(max(heights) > max_y):\n",
    "            max_y = max(heights)\n",
    "        plt.bar(x = [i*3+ind*(1.5*width)-(1.5*width*(len(sub_reddits_in_group)-1)/2) for i in range(len(categories))], height=heights, width=width, color=cmap[ind])\n",
    "    plt.xticks([i*3 for i in range(len(categories))],[j.replace('_', ' ') for j in categories])\n",
    "    plt.legend(sub_reddits_in_group)\n",
    "    plt.title('News tendencies for sub-reddits in group: ' + group, fontsize=20)\n",
    "    plt.ylabel('relative percentage', fontsize=16)\n",
    "    plt.yticks([i/10 for i in range(min(11,int(max_y*10) + 2))], [str(i*10)+'%' for i in range(min(11,int(max_y*10) + 2))])\n",
    "    plt.savefig('./categories/' + group + '_news.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_post_dic = {}\n",
    "\n",
    "for row in df.iterrows():\n",
    "    data = row[1]\n",
    "    documents = data['documents']\n",
    "    \n",
    "    for doc_id, text, date, sub_reddit, labels in documents:\n",
    "        if sub_reddit not in all_post_dic:\n",
    "            all_post_dic[sub_reddit] = {'total_posts': 0, 'real_news': 0, 'fake_news': 0}\n",
    "        all_post_dic[sub_reddit]['total_posts'] += 1\n",
    "        if len(labels) == 1:\n",
    "            fake = False\n",
    "            \n",
    "            # If any fakenews in post mark post as fake\n",
    "            # If counting everything: 'real_news': 102024, 'fake_news': 10557\n",
    "            # If any label is fake_news lable as fake_news: 'real_news': 69182, 'fake_news': 8884\n",
    "            for page, fake_news, political_bias, factual_bias in labels:\n",
    "                if fake_news == 1:\n",
    "                    fake = True\n",
    "                    break\n",
    "            \n",
    "            if fake:\n",
    "                all_post_dic[sub_reddit]['fake_news'] += 1\n",
    "            else:\n",
    "                all_post_dic[sub_reddit]['real_news'] += 1\n",
    "\n",
    "all_post_dic['TOTAL'] = {'total_posts': 0, 'real_news': 0, 'fake_news': 0}\n",
    "for theme in theme_groups:\n",
    "    sub_reddits = theme_groups[theme]\n",
    "    all_post_dic[theme] = {'total_posts': 0, 'real_news': 0, 'fake_news': 0}\n",
    "    for sub_reddit in sub_reddits:\n",
    "        all_post_dic[theme]['total_posts'] += all_post_dic[sub_reddit]['total_posts']\n",
    "        all_post_dic[theme]['real_news'] += all_post_dic[sub_reddit]['real_news']\n",
    "        all_post_dic[theme]['fake_news'] += all_post_dic[sub_reddit]['fake_news']\n",
    "    all_post_dic['TOTAL']['total_posts'] += all_post_dic[theme]['total_posts']\n",
    "    all_post_dic['TOTAL']['real_news'] += all_post_dic[theme]['real_news']\n",
    "    all_post_dic['TOTAL']['fake_news'] += all_post_dic[theme]['fake_news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_post_dic['TOTAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('num_docs', sum(df['num_docs']))\n",
    "print('fn', sum(df['fn_amounts']))\n",
    "print('rn', sum(df['rn_amounts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disable_box(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    \n",
    "def make_dist_bar(n, key, title, all_post_dic, subs, ax, cmap):\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    s_dic = {}\n",
    "    col_ind = {}\n",
    "    for ind, sub in enumerate(subs):\n",
    "        s_dic[sub] = all_post_dic[sub][key]\n",
    "        col_ind[sub] = ind\n",
    "    s_dic = {k: v for k, v in sorted(s_dic.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    x_ticks = {}\n",
    "    cur_n = 0\n",
    "    for ind, sub in enumerate(s_dic):\n",
    "        percentage = all_post_dic[sub][key]/n\n",
    "        ax.barh(0, percentage, left=cur_n, color=cmap[col_ind[sub]], edgecolor=cmap[col_ind[sub]], alpha=0.5)\n",
    "        if percentage > 0.1:\n",
    "            x_ticks[sub] = cur_n + percentage/2\n",
    "            n_points = int(percentage/0.05)\n",
    "            left = (percentage - 0.05*n_points)/2\n",
    "            if sub in bias['pro']:\n",
    "                m = '+'\n",
    "            elif sub in bias['anit']:\n",
    "                m = '_'\n",
    "            elif sub in bias['unbiased']:\n",
    "                m = 'o'\n",
    "            else:\n",
    "                cur_n += percentage\n",
    "                continue\n",
    "                \n",
    "            ax.scatter(np.arange(cur_n+0.05+left, cur_n+percentage-0.05, 0.05), [0]*(n_points-1), marker = m, s= 45, c='black')\n",
    "            ax.scatter(np.arange(cur_n+0.025+left, cur_n+percentage-0.025, 0.05), [0.2]*(n_points), marker = m, s= 45, c='black')\n",
    "            ax.scatter(np.arange(cur_n+0.025+left, cur_n+percentage-0.025, 0.05), [-0.2]*(n_points), marker = m, s= 45, c='black')\n",
    "        cur_n += percentage\n",
    "    \n",
    "    \n",
    "    ax.set_xticks(list(x_ticks.values()))\n",
    "    ax.set_xticklabels(list(x_ticks.keys()))\n",
    "    #ax.set_yticks([])\n",
    "    ax.figure.set_size_inches(15, 8)\n",
    "\n",
    "def make_dist_plot(group, subs):\n",
    "    data = all_post_dic[group]\n",
    "    fig, ax = plt.subplots(5, 1, figsize=(12,8))\n",
    "    plt.subplots_adjust(hspace=1.5, wspace=0)\n",
    "    n = data['total_posts']\n",
    "    rn = data['real_news']\n",
    "    fn = data['fake_news']\n",
    "\n",
    "    for a in ax:\n",
    "        disable_box(a)\n",
    "    ax[0].set_title('Overall distribution of labeled and unlabeled posts')\n",
    "    ax[0].barh(0,(rn+fn)/n, color='red', left=0)\n",
    "    ax[0].barh(0,(n-(rn+fn))/n, color='steelblue', left=(rn+fn)/n)\n",
    "    ax[0].set_xticks([0.5*(rn+fn)/n, 0.5*(n-(rn+fn))/n + (rn+fn)/n])\n",
    "    ax[0].set_xticklabels(['Labeled Posts - {:.3f}%'.format(100*(rn+fn)/n), 'Unlabeled Posts - {:.3f}%'.format(100*(n-(rn+fn))/n)])\n",
    "    ax[0].set_yticks([]);\n",
    "\n",
    "    labeled_n = rn+fn\n",
    "    ax[1].set_title('Distribution of real and fake news in labeled posts')\n",
    "    ax[1].barh(0,rn/labeled_n, color='orange', left=0)\n",
    "    ax[1].barh(0,fn/labeled_n, color='indianred', left=rn/labeled_n)\n",
    "    ax[1].set_xticks([0.5*rn/labeled_n, 0.5*fn/labeled_n + rn/labeled_n])\n",
    "    ax[1].set_xticklabels(['Real News Posts - {:.3f}%'.format(100*rn/labeled_n), 'Fake News Posts - {:.3f}%'.format(100*fn/labeled_n)])\n",
    "    ax[1].set_yticks([]);\n",
    "\n",
    "    # custom colormap. len = 12, since the biggest category consists out of 12 sub-reddits\n",
    "    cmap = ['orangered', 'darkmagenta', 'aqua', 'violet', 'gold', 'grey', 'blue', 'lime', 'steelblue', 'silver', 'deeppink', 'olivedrab']\n",
    "    \n",
    "    ##### TOTAL POSTS #####\n",
    "    make_dist_bar(n, 'total_posts', 'Distribution of all labeled posts', all_post_dic, subs, ax[2], cmap)\n",
    "    \n",
    "    ##### REAL NEWS #####\n",
    "    make_dist_bar(rn, 'real_news', 'Distribution of real news in groups',all_post_dic, subs, ax[3], cmap)\n",
    "\n",
    "    ##### FAKE NEWS #####\n",
    "    make_dist_bar(fn, 'fake_news', 'Distribution of fake news in groups',all_post_dic, subs, ax[4], cmap)\n",
    "    \n",
    "    #plt.savefig('./categories/' + group + '_dist.pdf', bbox_inches='tight')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for group in theme_groups:\n",
    "    subs = theme_groups[group]\n",
    "    make_dist_plot(group, subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_post_dic['general-political-debate'])\n",
    "s = 0;\n",
    "for sub in theme_groups['general-political-debate']:\n",
    "    print(all_post_dic[sub])\n",
    "    s += all_post_dic[sub]['fake_news']\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0.2, 0.4, 0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
