{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4ab4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e480df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/reddit_corpus_balanced_filtered.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234f176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary for theme groups\n",
    "theme_groups = {}\n",
    "theme_groups['SARS-CoV-2'] = ['r/CovidVaccinated', 'r/Masks4All', 'r/NoLockdownsNoMasks', 'r/EndTheLockdowns', 'r/COVID19', 'r/COVID19positive', 'r/CoronavirusCanada', 'r/CoronavirusRecession', 'r/CoronavirusUK', 'r/CoronavirusUS', 'r/Coronavirus', 'r/LockdownSkepticism', 'r/NoNewNormal']\n",
    "theme_groups['Vaccines'] = ['r/CovidVaccinated', 'r/VACCINES', 'r/vaxxhappened', 'r/AntiVaxxers', 'r/antivax', 'r/TrueAntiVaccination', 'r/DebateVaccine', 'r/DebateVaccines']\n",
    "theme_groups['Abortion'] = ['r/AskProchoice', 'r/prochoice', 'r/insaneprolife', 'r/prolife', 'r/ProLifeLibertarians', 'r/Abortiondebate', 'r/abortion']\n",
    "theme_groups['womens-and-mens-rights'] = ['r/Feminism', 'r/feminisms', 'r/RadicalFeminism', 'r/RadicalFeminismUSA', 'r/MRActivism', 'r/MensRights', 'r/antifeminists', 'r/feminismformen', 'r/masculism', 'r/GenderCritical', 'r/Egalitarianism']\n",
    "theme_groups['Gun-control'] = ['r/Firearms', 'r/GunsAreCool', 'r/liberalgunowners', 'r/progun', 'r/guncontrol', 'r/GunDebates', 'r/GunResearch', 'r/gunpolitics']\n",
    "theme_groups['Climate-change'] = ['r/climateskeptics', 'r/GlobalClimateChange', 'r/climate', 'r/climatechange']\n",
    "theme_groups['5G'] = ['r/5GDebate']\n",
    "theme_groups['general-political-debate'] = ['r/JoeBiden', 'r/LeftistsForMen', 'r/Liberal', 'r/LockdownCriticalLeft', 'r/democrats', 'r/Conservative', 'r/ConservativesOnly', 'r/conservatives', 'r/Republican', 'r/RepublicanValues', 'r/politics', 'r/uspolitics']\n",
    "\n",
    "bias = {}\n",
    "bias['pro'] = ['r/CovidVaccinated', 'r/Masks4All', 'r/CovidVaccinated', 'r/VACCINES', 'r/vaxxhappened', 'r/AskProchoice', 'r/prochoice', 'r/insaneprolife', 'r/Firearms', 'r/GunsAreCool',  'r/liberalgunowners',  'r/progun']\n",
    "bias['anit'] = ['r/NoLockdownsNoMasks', 'r/EndTheLockdowns', 'r/AntiVaxxers',  'r/antivax',  'r/TrueAntiVaccination', 'r/prolife', 'r/ProLifeLibertarians', 'r/guncontrol']\n",
    "bias['unbiased'] = ['r/COVID19', 'r/COVID19positive', 'r/CoronavirusCanada','r/CoronavirusRecession','r/CoronavirusUK','r/CoronavirusUS','r/Coronavirus','r/LockdownSkepticism','r/DebateVaccine','r/DebateVaccines','r/Abortiondebate','r/abortion', 'r/GunDebates','r/GunResearch','r/gunpolitics', 'r/ImpeachTrump']\n",
    "\n",
    "# !ProLifeLibertarians is missing any labled data\n",
    "\n",
    "#theme_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28968107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data and sort to dictionaries for later plots\n",
    "sub_reddit_dic = {}\n",
    "\n",
    "for row in df.iterrows():\n",
    "    data = row[1]\n",
    "    documents = data['documents']\n",
    "    \n",
    "    for doc_id, text, date, sub_reddit, labels in documents:\n",
    "        if len(labels) == 1:\n",
    "            if sub_reddit not in sub_reddit_dic:\n",
    "                sub_reddit_dic[sub_reddit] = {'politics': {'count':0,'LEFT_CENTER':0,'LEFT':0,'LEAST_BIASED':0,'RIGHT_CENTER':0,'SATIRE':0,'PRO_SCIENCE':0,'RIGHT':0,'EXTREME_LEFT':0,'CONSPIRACY_PSEUDOSCIENCE':0,'EXTREME_RIGHT':0,'PRO_RUSSIAN_PROPAGANDA':0}, 'news': {'count':0,'HIGH':0,'VERY_HIGH':0,'MOSTLY_FACTUAL':0,'MIXED':0,'VERY_LOW':0,'LOW':0}}\n",
    "            for label in labels:\n",
    "                pol_bias = label[2][0]\n",
    "                news_bias = label[3]\n",
    "                if len(pol_bias) > 0:\n",
    "                    sub_reddit_dic[sub_reddit]['politics'][pol_bias] += 1\n",
    "                    sub_reddit_dic[sub_reddit]['politics']['count'] += 1\n",
    "                if (len(news_bias) > 0):\n",
    "                    sub_reddit_dic[sub_reddit]['news'][news_bias] += 1\n",
    "                    sub_reddit_dic[sub_reddit]['news']['count'] += 1\n",
    "\n",
    "                    \n",
    "theme_dic = {}\n",
    "\n",
    "for theme in theme_groups:\n",
    "    theme_dic[theme] = {'politics': {'count':0,'LEFT_CENTER':0,'LEFT':0,'LEAST_BIASED':0,'RIGHT_CENTER':0,'SATIRE':0,'PRO_SCIENCE':0,'RIGHT':0,'EXTREME_LEFT':0,'CONSPIRACY_PSEUDOSCIENCE':0,'EXTREME_RIGHT':0,'PRO_RUSSIAN_PROPAGANDA':0}, 'news': {'count':0,'HIGH':0,'VERY_HIGH':0,'MOSTLY_FACTUAL':0,'MIXED':0,'VERY_LOW':0,'LOW':0}}\n",
    "    for sub_reddit in theme_groups[theme]:\n",
    "        if sub_reddit not in sub_reddit_dic:\n",
    "            continue\n",
    "        for i in sub_reddit_dic[sub_reddit]['politics']:\n",
    "            theme_dic[theme]['politics'][i] += sub_reddit_dic[sub_reddit]['politics'][i]\n",
    "        for i in sub_reddit_dic[sub_reddit]['news']:\n",
    "            theme_dic[theme]['news'][i] += sub_reddit_dic[sub_reddit]['news'][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a54d72",
   "metadata": {},
   "source": [
    "## Political Bias plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ff66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of factual factor distribution in categories. Single Plot\n",
    "cmap = ['orangered', 'lime', 'aqua', 'violet', 'gold', 'grey', 'blue', 'darkmagenta']\n",
    "categories = ['VERY_HIGH','HIGH','MOSTLY_FACTUAL','MIXED','LOW','VERY_LOW']\n",
    "width = 1/len(theme_dic)\n",
    "max_y = 0\n",
    "for ind, theme in enumerate(theme_dic):\n",
    "    data = theme_dic[theme]['news']\n",
    "    n = data['count']\n",
    "    heights = [data[i]/n if i in data else 0 for i in categories]\n",
    "    if(max(heights) > max_y):\n",
    "            max_y = max(heights)\n",
    "    plt.bar(x = [i*3+ind*(1.5*width)-(1.5*width*(len(theme_dic)-1)/2) for i in range(len(categories))], height=heights, width=width, color=cmap[ind])\n",
    "plt.xticks([i*3 for i in range(len(categories))],categories)\n",
    "plt.legend(theme_dic)\n",
    "plt.ylabel(\"relative percentage\")\n",
    "plt.yticks([i/10 for i in range(min(11,int(max_y*10) + 2))], [str(i*10)+'%' for i in range(min(11,int(max_y*10) + 2))])\n",
    "plt.title(\"Factual factors in all posts\")\n",
    "plt.savefig(\"../plots/post_level_overview/factual_factor.pdf\")\n",
    "plt.show()\n",
    "\n",
    "# Plot of political distribution in categories. Single Plot\n",
    "categories = ['EXTREME_LEFT','LEFT','LEFT_CENTER','LEAST_BIASED','RIGHT_CENTER','RIGHT','EXTREME_RIGHT']# ,'CONSPIRACY_PSEUDOSCIENCE','PRO_RUSSIAN_PROPAGANDA', 'PRO_SCIENCE']\n",
    "max_y = 0\n",
    "for ind, theme in enumerate(theme_dic):\n",
    "    data = theme_dic[theme]['politics']\n",
    "    n = data['count'] - data['CONSPIRACY_PSEUDOSCIENCE'] - data['PRO_RUSSIAN_PROPAGANDA'] - data['PRO_SCIENCE']\n",
    "    heights = [data[i]/n if i in data else 0 for i in categories]\n",
    "    if(max(heights) > max_y):\n",
    "            max_y = max(heights)\n",
    "    plt.bar(x = [i*3+ind*(1.5*width)-(1.5*width*(len(theme_dic)-1)/2) for i in range(len(categories))], height=heights, width=width, color=cmap[ind])\n",
    "plt.xticks([i*3 for i in range(len(categories))],[j if ind % 2 == 0 else \" \\n\"+j for ind,j in enumerate(categories)])\n",
    "plt.legend(theme_dic)\n",
    "plt.ylabel(\"relative percentage\")\n",
    "plt.yticks([i/10 for i in range(min(11,int(max_y*10) + 2))], [str(i*10)+'%' for i in range(min(11,int(max_y*10) + 2))])\n",
    "plt.title(\"Political bias in all posts\")\n",
    "plt.savefig(\"../plots/post_level_overview/political_bias.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36975a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each subreddit of a category\n",
    "\n",
    "# custom colormap. len = 12, since the biggest category consists out of 12 sub-reddits\n",
    "cmap = ['orangered', 'darkmagenta', 'aqua', 'violet', 'gold', 'grey', 'blue', 'lime', 'steelblue', 'silver', 'deeppink', 'olivedrab']\n",
    "\n",
    "# POLITICAL BIAS\n",
    "# Ignore certian categories\n",
    "categories = ['EXTREME_LEFT','LEFT','LEFT_CENTER','LEAST_BIASED','RIGHT_CENTER','RIGHT','EXTREME_RIGHT']#,'CONSPIRACY_PSEUDOSCIENCE','PRO_RUSSIAN_PROPAGANDA','PRO_SCIENCE']\n",
    "for group in theme_groups:\n",
    "    max_y = 0\n",
    "    \n",
    "    sub_reddits_in_group = [i for i in theme_groups[group] if i in sub_reddit_dic]\n",
    "    for ind, sub_reddit in enumerate(sub_reddits_in_group):\n",
    "        \n",
    "        data = sub_reddit_dic[sub_reddit]['politics']\n",
    "        # normalization\n",
    "        n = data['count'] - data['CONSPIRACY_PSEUDOSCIENCE'] - data['PRO_RUSSIAN_PROPAGANDA'] - data['PRO_SCIENCE']\n",
    "        if n == 0:\n",
    "            continue\n",
    "        \n",
    "        width = 1/len(sub_reddits_in_group)\n",
    "\n",
    "        # extract each bar height\n",
    "        heights = [data[i]/n if i in data else 0 for i in categories]\n",
    "        \n",
    "        # max hight for y-axis labels, needed for tick legend\n",
    "        if(max(heights) > max_y):\n",
    "            max_y = max(heights)\n",
    "        \n",
    "        plt.bar(x = [i*3+ind*(1.5*width)-(1.5*width*(len(sub_reddits_in_group)-1)/2) for i in range(len(categories))], height=heights, width=width, color=cmap[ind])\n",
    "    \n",
    "    # finishing plot with title, labels and ticks.\n",
    "    plt.xticks([i*3 for i in range(len(categories))],[j.replace('_', ' ') for j in categories])\n",
    "    plt.legend(sub_reddits_in_group)\n",
    "    plt.title('Political tendencies for sub-reddits in group: ' + group)\n",
    "    plt.ylabel('relative percentage')\n",
    "    plt.yticks([i/10 for i in range(min(11,int(max_y*10) + 2))], [str(i*10)+'%' for i in range(min(11,int(max_y*10) + 2))])\n",
    "    plt.savefig('../plots/topic_group_distributions/' + group + '/political_bias.pdf')\n",
    "    plt.show()\n",
    "\n",
    "# FACTUAL STRUCTURE\n",
    "categories = ['VERY_HIGH','HIGH','MOSTLY_FACTUAL','MIXED','LOW','VERY_LOW']\n",
    "for group in theme_groups:\n",
    "    max_y = 0\n",
    "    # Dont iterate over sub-reddits with no labeled data\n",
    "    sub_reddits_in_group = [i for i in theme_groups[group] if i in sub_reddit_dic]\n",
    "    for ind, sub_reddit in enumerate(sub_reddits_in_group):\n",
    "\n",
    "        # \n",
    "        if (sub_reddit not in sub_reddit_dic):\n",
    "            continue\n",
    "        data = sub_reddit_dic[sub_reddit]['news']\n",
    "        n = data['count']\n",
    "        width = 1/len(sub_reddits_in_group)\n",
    "        heights = [data[i]/n if i in data else 0 for i in categories]\n",
    "        if(max(heights) > max_y):\n",
    "            max_y = max(heights)\n",
    "        plt.bar(x = [i*3+ind*(1.5*width)-(1.5*width*(len(sub_reddits_in_group)-1)/2) for i in range(len(categories))], height=heights, width=width, color=cmap[ind])\n",
    "    plt.xticks([i*3 for i in range(len(categories))],[j.replace('_', ' ') for j in categories])\n",
    "    plt.legend(sub_reddits_in_group)\n",
    "    plt.title('Factuality for sub-reddits in group: ' + group)\n",
    "    plt.ylabel('relative percentage')\n",
    "    plt.yticks([i/10 for i in range(min(11,int(max_y*10) + 2))], [str(i*10)+'%' for i in range(min(11,int(max_y*10) + 2))])\n",
    "    plt.savefig('../plots/topic_group_distributions/' + group + '/factual_factor.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_post_dic = {}\n",
    "\n",
    "for row in df.iterrows():\n",
    "    data = row[1]\n",
    "    documents = data['documents']\n",
    "    \n",
    "    for doc_id, text, date, sub_reddit, labels in documents:\n",
    "        if sub_reddit not in all_post_dic:\n",
    "            all_post_dic[sub_reddit] = {'total_posts': 0, 'real_news': 0, 'fake_news': 0, 'LEFT_CENTER':0,'LEFT':0,'LEAST_BIASED':0,'RIGHT_CENTER':0,'RIGHT':0,'EXTREME_LEFT':0, 'EXTREME_RIGHT':0}\n",
    "        all_post_dic[sub_reddit]['total_posts'] += 1\n",
    "        if len(labels) == 1:\n",
    "            \n",
    "            if labels[0][1] == 1:\n",
    "                all_post_dic[sub_reddit]['fake_news'] += 1\n",
    "            else:\n",
    "                all_post_dic[sub_reddit]['real_news'] += 1\n",
    "            \n",
    "            pol_bias = labels[0][2][0]\n",
    "            if len(pol_bias) > 0 and pol_bias in all_post_dic[sub_reddit]:\n",
    "                all_post_dic[sub_reddit][pol_bias] += 1\n",
    "            \n",
    "\n",
    "all_post_dic['TOTAL'] = {'total_posts': 0, 'real_news': 0, 'fake_news': 0, 'LEFT_CENTER':0,'LEFT':0,'LEAST_BIASED':0,'RIGHT_CENTER':0,'RIGHT':0,'EXTREME_LEFT':0, 'EXTREME_RIGHT':0}\n",
    "for theme in theme_groups:\n",
    "    sub_reddits = theme_groups[theme]\n",
    "    all_post_dic[theme] = {'total_posts': 0, 'real_news': 0, 'fake_news': 0, 'LEFT_CENTER':0,'LEFT':0,'LEAST_BIASED':0,'RIGHT_CENTER':0,'RIGHT':0,'EXTREME_LEFT':0, 'EXTREME_RIGHT':0}\n",
    "    for sub_reddit in sub_reddits:\n",
    "        all_post_dic[theme]['total_posts'] += all_post_dic[sub_reddit]['total_posts']\n",
    "        all_post_dic[theme]['real_news'] += all_post_dic[sub_reddit]['real_news']\n",
    "        all_post_dic[theme]['fake_news'] += all_post_dic[sub_reddit]['fake_news']\n",
    "        all_post_dic[theme]['EXTREME_LEFT'] += all_post_dic[sub_reddit]['EXTREME_LEFT']\n",
    "        all_post_dic[theme]['LEFT'] += all_post_dic[sub_reddit]['LEFT']\n",
    "        all_post_dic[theme]['LEFT_CENTER'] += all_post_dic[sub_reddit]['LEFT_CENTER']\n",
    "        all_post_dic[theme]['LEAST_BIASED'] += all_post_dic[sub_reddit]['LEAST_BIASED']\n",
    "        all_post_dic[theme]['RIGHT_CENTER'] += all_post_dic[sub_reddit]['RIGHT_CENTER']\n",
    "        all_post_dic[theme]['RIGHT'] += all_post_dic[sub_reddit]['RIGHT']\n",
    "        all_post_dic[theme]['EXTREME_RIGHT'] += all_post_dic[sub_reddit]['EXTREME_RIGHT']\n",
    "    all_post_dic['TOTAL']['total_posts'] += all_post_dic[theme]['total_posts']\n",
    "    all_post_dic['TOTAL']['real_news'] += all_post_dic[theme]['real_news']\n",
    "    all_post_dic['TOTAL']['fake_news'] += all_post_dic[theme]['fake_news']\n",
    "    all_post_dic['TOTAL']['EXTREME_LEFT'] += all_post_dic[theme]['EXTREME_LEFT']\n",
    "    all_post_dic['TOTAL']['LEFT'] += all_post_dic[theme]['LEFT']\n",
    "    all_post_dic['TOTAL']['LEFT_CENTER'] += all_post_dic[theme]['LEFT_CENTER']\n",
    "    all_post_dic['TOTAL']['LEAST_BIASED'] += all_post_dic[theme]['LEAST_BIASED']\n",
    "    all_post_dic['TOTAL']['RIGHT_CENTER'] += all_post_dic[theme]['RIGHT_CENTER']\n",
    "    all_post_dic['TOTAL']['RIGHT'] += all_post_dic[theme]['RIGHT']\n",
    "    all_post_dic['TOTAL']['EXTREME_RIGHT'] += all_post_dic[theme]['EXTREME_RIGHT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7358a219",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_post_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd0559",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('num_docs', sum(df['num_docs']))\n",
    "print('fn', sum(df['fn_amounts']))\n",
    "print('rn', sum(df['rn_amounts']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ab02d1",
   "metadata": {},
   "source": [
    "## Bar Plots for the different subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e68a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake news / Real news dist\n",
    "\n",
    "def disable_box(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    \n",
    "def make_dist_bar(n, key, title, all_post_dic, subs, ax, cmap):\n",
    "    \"\"\"\n",
    "    Method to make the subreddit based stacked bar distribution\n",
    "\n",
    "    n: total number of posts\n",
    "    key: ['total_posts', 'real_news', 'fake_news'], used to declare which bar should be produced\n",
    "    title: title for the axis\n",
    "    all_post_dic: dictionary holding the data\n",
    "    subs: List of subreddits\n",
    "    ax: axis object which will host the plot\n",
    "    cmap: colormap for the stacked bar\n",
    "    \"\"\"\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    s_dic = {}\n",
    "    col_ind = {}\n",
    "    for ind, sub in enumerate(subs):\n",
    "        s_dic[sub] = all_post_dic[sub][key]\n",
    "        col_ind[sub] = ind\n",
    "    s_dic = {k: v for k, v in sorted(s_dic.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    x_ticks = {}\n",
    "    percentages = {}\n",
    "    cur_n = 0\n",
    "    for ind, sub in enumerate(s_dic):\n",
    "        percentage = all_post_dic[sub][key]/n\n",
    "        percentages[sub] = percentage\n",
    "        ax.barh(0, percentage, left=cur_n, color=cmap[col_ind[sub]], edgecolor=cmap[col_ind[sub]], alpha=0.5, label=sub)\n",
    "        if percentage > 0.1:\n",
    "            x_ticks[sub] = cur_n + percentage/2\n",
    "            n_points = int(percentage/0.05)\n",
    "            left = (percentage - 0.05*n_points)/2\n",
    "            if sub in bias['pro']:\n",
    "                m = '+'\n",
    "            elif sub in bias['anit']:\n",
    "                m = 'x'\n",
    "            elif sub in bias['unbiased']:\n",
    "                m = 'o'\n",
    "            else:\n",
    "                cur_n += percentage\n",
    "                continue\n",
    "                \n",
    "\n",
    "            # fill in pro/contra/neutral markers if present\n",
    "            if m == 'o':\n",
    "                pass\n",
    "                # not using neutral marker anymore to prevent plot overload\n",
    "                # ax.scatter(np.arange(cur_n+0.05+left, cur_n+percentage-0.05, 0.05), [0]*(n_points-1), marker = m, s= 45, facecolors='none', edgecolors='black')\n",
    "                # ax.scatter(np.arange(cur_n+0.025+left, cur_n+percentage-0.025, 0.05), [0.2]*(n_points), marker = m, s= 45, facecolors='none', edgecolors='black')\n",
    "                # ax.scatter(np.arange(cur_n+0.025+left, cur_n+percentage-0.025, 0.05), [-0.2]*(n_points), marker = m, s= 45, facecolors='none', edgecolors='black')\n",
    "            \n",
    "            else:\n",
    "                ax.scatter(np.arange(cur_n+0.05+left, cur_n+percentage-0.05, 0.05), [0]*(n_points-1), marker = m, s= 45, c='black')\n",
    "                ax.scatter(np.arange(cur_n+0.025+left, cur_n+percentage-0.025, 0.05), [0.2]*(n_points), marker = m, s= 45, c='black')\n",
    "                ax.scatter(np.arange(cur_n+0.025+left, cur_n+percentage-0.025, 0.05), [-0.2]*(n_points), marker = m, s= 45, c='black')\n",
    "            \n",
    "        cur_n += percentage\n",
    "    \n",
    "    \n",
    "    ax.set_xticks(list(x_ticks.values()))\n",
    "    ax.set_xticklabels([i + '\\n' + '{:.2f}%'.format(percentages[i]*100) for i in list(x_ticks.keys())])\n",
    "    ax.set_yticks([])\n",
    "    ax.figure.set_size_inches(15, 8)\n",
    "    return col_ind\n",
    "\n",
    "def make_dist_plot(group, subs):\n",
    "    data = all_post_dic[group]\n",
    "    _ , ax = plt.subplots(5, 1, figsize=(12.1,8.1))\n",
    "    plt.subplots_adjust(hspace=1.5, wspace=0)\n",
    "    n = data['total_posts']\n",
    "    rn = data['real_news']\n",
    "    fn = data['fake_news']\n",
    "\n",
    "    for a in ax:\n",
    "        disable_box(a)\n",
    "    ax[0].set_title('Overall distribution of labeled and unlabeled posts in posts')\n",
    "    ax[0].barh(0,(rn+fn)/n, color='red', left=0)\n",
    "    ax[0].barh(0,(n-(rn+fn))/n, color='steelblue', left=(rn+fn)/n)\n",
    "    ax[0].set_xticks([0.5*(rn+fn)/n, 0.5*(n-(rn+fn))/n + (rn+fn)/n])\n",
    "    ax[0].set_xticklabels(['Labeled Posts - {:.2f}%'.format(100*(rn+fn)/n), 'Unlabeled Posts - {:.2f}%'.format(100*(n-(rn+fn))/n)])\n",
    "    ax[0].set_yticks([]);\n",
    "\n",
    "    labeled_n = rn+fn\n",
    "    ax[1].set_title('Distribution of real and fake news in labeled posts')\n",
    "    ax[1].barh(0,rn/labeled_n, color='orange', left=0)\n",
    "    ax[1].barh(0,fn/labeled_n, color='indianred', left=rn/labeled_n)\n",
    "    ax[1].set_xticks([0.5*rn/labeled_n, 0.5*fn/labeled_n + rn/labeled_n])\n",
    "    ax[1].set_xticklabels(['Real News Posts - {:.2f}%'.format(100*rn/labeled_n), 'Fake News Posts - {:.2f}%'.format(100*fn/labeled_n)])\n",
    "    ax[1].set_yticks([]);\n",
    "\n",
    "    # custom colormap. len = 12, since the biggest category consists out of 12 sub-reddits\n",
    "    cmap = ['orangered', 'darkmagenta', 'aqua', 'violet', 'gold', 'grey', 'blue', 'lime', 'steelblue', 'silver', 'deeppink', 'olivedrab']\n",
    "    \n",
    "    ##### TOTAL POSTS #####\n",
    "    make_dist_bar(n, 'total_posts', 'Distribution of all labeled posts', all_post_dic, subs, ax[2], cmap)\n",
    "    \n",
    "    ##### REAL NEWS #####\n",
    "    make_dist_bar(rn, 'real_news', 'Distribution of real news in groups',all_post_dic, subs, ax[3], cmap)\n",
    "\n",
    "    ##### FAKE NEWS #####\n",
    "    make_dist_bar(fn, 'fake_news', 'Distribution of fake news in groups',all_post_dic, subs, ax[4], cmap)\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.2, 8))\n",
    "    plt.savefig('../plots/topic_group_distributions/' + group + '/post_distribution.pdf', bbox_inches='tight')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f94eec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# runner cell to create all plots\n",
    "for group in theme_groups:\n",
    "    subs = theme_groups[group]\n",
    "    make_dist_plot(group, subs)\n",
    "make_dist_plot('TOTAL', list(theme_groups.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80107d73",
   "metadata": {},
   "source": [
    "## Creation times and topic distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b1bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import datetime\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"pastel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f3812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inverse dic\n",
    "inv_theme_groups = {}\n",
    "for k in theme_groups:\n",
    "    for v in theme_groups[k]:\n",
    "        inv_theme_groups[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba786b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_list = []\n",
    "for row in df.iterrows():\n",
    "    data = row[1]\n",
    "    documents = data['documents']\n",
    "    \n",
    "    for doc_id, text, date, sub_reddit, labels in documents:\n",
    "        if len(labels) != 0 and sub_reddit in inv_theme_groups:\n",
    "            post_list.append({'Publishing Time': date, 'Topic': inv_theme_groups[sub_reddit]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df = pd.DataFrame(post_list)\n",
    "post_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b9887",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data = post_df[post_df['Publishing Time'] > '01.01.2018'], x='Publishing Time', hue='Topic', common_norm=False)\n",
    "plt.xlim([datetime.date(year=2018, month=1, day=1), datetime.date(year=2021, month=7, day=1)])\n",
    "plt.xticks([datetime.date(year=2018 + i, month=1, day=1) for i in range(4)], ['2018', '2019', '2020', '2021'])\n",
    "plt.title('Distribution of publishing times in all topic groups')\n",
    "plt.savefig('../plots/topic_group_distributions/posting_times.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f199bb",
   "metadata": {},
   "source": [
    "## Annotations per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d20f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['rn_amounts'] + df['fn_amounts'], hue=df['fake_news_spreader'], binwidth=3)\n",
    "plt.xlim([1,80])\n",
    "plt.title('Number of labeled post grouped by misinformation and real news spreaders')\n",
    "plt.xlabel('Number of labeled posts')\n",
    "plt.ylabel('Number of users')\n",
    "plt.legend(loc='upper right', labels=['Real News Spreader', 'Misinformation Spreader'])\n",
    "plt.savefig('../plots/user_annotations.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350abf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ca1dab13569cba37c96f77d2e230d532249c1dfc43abceb441f3610f1bfff28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
