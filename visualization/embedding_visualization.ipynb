{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc266562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26e0e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/post_emb.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c61abcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/reddit_corpus_balanced_filtered.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b65fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_info = {}\n",
    "\n",
    "for row in tqdm(df.iterrows(), total=len(df)):\n",
    "    data = row[1]\n",
    "    documents = data['documents']\n",
    "    \n",
    "    for doc_id, text, date, sub_reddit, labels in documents:\n",
    "        if len(labels) == 1 and len(labels[0][2][0]) > 0:\n",
    "            id_to_info[doc_id] = {'s': sub_reddit}\n",
    "            if labels[0][1] == 1:\n",
    "                id_to_info[doc_id]['n'] = 'Fake'\n",
    "            else:\n",
    "                id_to_info[doc_id]['n'] = 'Real'\n",
    "            id_to_info[doc_id]['p'] = labels[0][2][0]\n",
    "        else:\n",
    "            if doc_id in embeddings:\n",
    "                del embeddings[doc_id]\n",
    "                \n",
    "for key in embeddings.keys():\n",
    "    if key not in id_to_info:\n",
    "        del embeddings[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e2369",
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_groups = {}\n",
    "theme_groups['SARS-CoV-2'] = ['r/CovidVaccinated', 'r/Masks4All', 'r/NoLockdownsNoMasks', 'r/EndTheLockdowns', 'r/COVID19', 'r/COVID19positive', 'r/CoronavirusCanada', 'r/CoronavirusRecession', 'r/CoronavirusUK', 'r/CoronavirusUS', 'r/Coronavirus', 'r/LockdownSkepticism', 'r/NoNewNormal']\n",
    "theme_groups['Vaccines'] = ['r/CovidVaccinated', 'r/VACCINES', 'r/vaxxhappened', 'r/AntiVaxxers', 'r/antivax', 'r/TrueAntiVaccination', 'r/DebateVaccine', 'r/DebateVaccines']\n",
    "theme_groups['Abortion'] = ['r/AskProchoice', 'r/prochoice', 'r/insaneprolife', 'r/prolife', 'r/ProLifeLibertarians', 'r/Abortiondebate', 'r/abortion']\n",
    "theme_groups['womens-and-mens-rights'] = ['r/Feminism', 'r/feminisms', 'r/RadicalFeminism', 'r/RadicalFeminismUSA', 'r/MRActivism', 'r/MensRights', 'r/antifeminists', 'r/feminismformen', 'r/masculism', 'r/GenderCritical', 'r/Egalitarianism']\n",
    "theme_groups['Gun-control'] = ['r/Firearms', 'r/GunsAreCool', 'r/liberalgunowners', 'r/progun', 'r/guncontrol', 'r/GunDebates', 'r/GunResearch', 'r/gunpolitics']\n",
    "theme_groups['Climate-change'] = ['r/climateskeptics', 'r/GlobalClimateChange', 'r/climate', 'r/climatechange']\n",
    "theme_groups['5G'] = ['r/5GDebate']\n",
    "theme_groups['general-political-debate'] = ['r/JoeBiden', 'r/LeftistsForMen', 'r/Liberal', 'r/LockdownCriticalLeft', 'r/democrats', 'r/Conservative', 'r/ConservativesOnly', 'r/conservatives', 'r/Republican', 'r/RepublicanValues', 'r/politics', 'r/uspolitics', 'r/Impeach_Trump']\n",
    "\n",
    "inverse_theme_groups = {}\n",
    "for theme in theme_groups:\n",
    "    for sub in theme_groups[theme]:\n",
    "        inverse_theme_groups[sub] = theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64881f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [id_to_info[i]['n'] + \"-News, \" + id_to_info[i]['p'] + \" bias, \" + id_to_info[i]['s'] + \"\\t\" + id_to_info[i]['n'] + \"\\t\" + id_to_info[i]['p'] + \"\\t\" + inverse_theme_groups[id_to_info[i]['s']] for i in list(embeddings.keys())]\n",
    "tensors = np.array([i.numpy() for i in list(embeddings.values())])\n",
    "\n",
    "log_dir = './embeddings/subreddits'\n",
    "\n",
    "if not os.path.isdir(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Save Labels separately on a line-by-line manner.\n",
    "with open(os.path.join(log_dir, 'metadata.tsv'), \"w\", encoding='utf-8') as f:\n",
    "    f.write(\"Index\\tNews\\tPolitical\\tSubreddit\\n\")\n",
    "    for subwords in labels:\n",
    "        f.write(\"{}\\n\".format(subwords))\n",
    "\n",
    "# Save the weights we want to analyze as a variable. Note that the first\n",
    "# value represents any unknown word, which is not in the metadata, here\n",
    "# we will remove this value.\n",
    "weights = tf.Variable(tensors)\n",
    "# Create a checkpoint from embedding, the filename and key are the\n",
    "# name of the tensor.\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "\n",
    "# Set up config.\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`.\n",
    "embedding.tensor_name = 'embedding/.ATTRIBUTES/VARIABLE_VALUE'\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(log_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6916a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_theme_groups = {}\n",
    "for theme in theme_groups:\n",
    "    for sub in theme_groups[theme]:\n",
    "        inverse_theme_groups[sub] = theme"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
