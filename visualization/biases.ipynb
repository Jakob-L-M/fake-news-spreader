{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92c22aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/reddit_corpus_balanced_filtered.gzip', compression='gzip')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80379e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "\n",
    "for row in tqdm(df.iterrows(), total=len(df)):\n",
    "    data = row[1]\n",
    "    documents = data['documents']\n",
    "    \n",
    "    for doc_id, text, date, sub_reddit, labels in documents:\n",
    "        if len(labels) == 1:\n",
    "            if labels[0][1] == 0:\n",
    "                    rn += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "            \n",
    "            if ('brainwashed' in text):\n",
    "                if labels[0][1] == 0:\n",
    "                    not_rn_c += 1\n",
    "                else:\n",
    "                    not_fn_c += 1\n",
    "            \n",
    "            for word in text.split(' '):\n",
    "                if word not in vocab:\n",
    "                    vocab[word] = 0\n",
    "                vocab[word] += 1\n",
    "\n",
    "print(not_fn_c, not_rn_c, (not_fn_c/fn)/(not_rn_c/rn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e857fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for word in dict(vocab):\n",
    "    if vocab[word] < 100:\n",
    "        del vocab[word]\n",
    "        c += 1\n",
    "\n",
    "\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c265330",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_score = {}\n",
    "rn = 0\n",
    "fn = 0\n",
    "\n",
    "for row in tqdm(df.iterrows(), total=len(df)):\n",
    "    data = row[1]\n",
    "    documents = data['documents']\n",
    "    \n",
    "    for doc_id, text, date, sub_reddit, labels in documents:\n",
    "        if len(labels) == 1:\n",
    "            if labels[0][1] == 0:\n",
    "                    rn += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "            \n",
    "            for word in vocab:\n",
    "                if word in text:\n",
    "                    if word not in vocab_score:\n",
    "                        vocab_score[word] = {'rn': 0, 'fn': 0}\n",
    "                    if labels[0][1] == 0:\n",
    "                        vocab_score[word]['rn'] += 1\n",
    "                    else:\n",
    "                        vocab_score[word]['fn'] += 1\n",
    "                        \n",
    "for word in vocab_score:\n",
    "    vocab_score[word]['score'] = (vocab_score[word]['fn']/fn)/(vocab_score[word]['fn']/fn + vocab_score[word]['rn']/rn)\n",
    "\n",
    "vocab_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd03ede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "act = []\n",
    "pred = []\n",
    "\n",
    "for row in tqdm(df.iterrows(), total=len(df)):\n",
    "    data = row[1]\n",
    "    documents = data['documents']\n",
    "    \n",
    "    for doc_id, text, date, sub_reddit, labels in documents:\n",
    "        if len(labels) == 1:\n",
    "            if labels[0][1] == 0:\n",
    "                act.append(0)\n",
    "            else:\n",
    "                act.append(1)\n",
    "            \n",
    "            rn = 0\n",
    "            fn = 0\n",
    "            done = False\n",
    "            for word in text.split(' '):\n",
    "                if word in vocab_score:\n",
    "                    if vocab_score[word]['score'] == 0:\n",
    "                        pred.append(0)\n",
    "                        done = True\n",
    "                        break\n",
    "                    rn -= log2(1-vocab_score[word]['score'])\n",
    "                    fn -= log2(vocab_score[word]['score'])\n",
    "            \n",
    "            if not done and rn <= fn:\n",
    "                pred.append(0)\n",
    "            else:\n",
    "                pred.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7316cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = sum(pred[i] == 1 and act[i] == 1 for i in range(len(act)))\n",
    "tn = sum(pred[i] == 0 and act[i] == 0 for i in range(len(act)))\n",
    "fp = sum(pred[i] == 1 and act[i] == 0 for i in range(len(act)))\n",
    "fn = sum(pred[i] == 0 and act[i] == 1 for i in range(len(act)))\n",
    "\n",
    "print(\"Pred\\Act FN \\t RN\\nFN \\t\" + str(tp) + \"\\t\" + str(fp) + \"\\nRN \\t\" + str(fn)+ \"\\t\" + str(tn))\n",
    "\n",
    "prec=tp/(tp+fp)\n",
    "rec=tp/(tp+fn)\n",
    "acc=(tp+tn)/(tp+tn+fp+fn)\n",
    "\n",
    "\n",
    "print(\"\\nprec:\", prec)\n",
    "print(\"rec:\", rec)\n",
    "print(\"acc:\", acc)\n",
    "print(\"F1:\", 2*(prec*rec)/(prec+rec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
