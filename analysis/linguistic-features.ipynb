{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c99c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import spacy\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Disable all unused parts to boost the calculation\n",
    "#nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser', 'lemmatizer', 'tok2vec', 'attribute_ruler', 'senter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefa7ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/reddit_corpus_balanced_filtered.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857276a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "user_features = {}\n",
    "for row in tqdm(df.iterrows(), desc='Evaluating Named Entities', total=len(df)):\n",
    "    data = row[1]\n",
    "    documents = data['documents']\n",
    "    user_id = data['user_id']\n",
    "    \n",
    "    user_features[user_id] = {'all': {}}\n",
    "    \n",
    "    for doc_id, text, date, sub_reddit, labels in documents:\n",
    "        \n",
    "        doc = nlp(text)\n",
    "        \n",
    "        user_features[user_id][doc_id] = {'tokens': len(doc)}\n",
    "        for token in doc:\n",
    "            if token.pos_ not in user_features[user_id][doc_id]:\n",
    "                user_features[user_id][doc_id][token.pos_] = 0\n",
    "            user_features[user_id][doc_id][token.pos_] += 1\n",
    "            \n",
    "        for pos in user_features[user_id][doc_id]:\n",
    "            if pos not in user_features[user_id]['all']:\n",
    "                user_features[user_id]['all'][pos] = 0\n",
    "            user_features[user_id]['all'][pos] += user_features[user_id][doc_id][pos]\n",
    "\n",
    "user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f66d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/linguistic_features.pickel', 'wb') as f:\n",
    "    pickle.dump(user_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a44bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/linguistic_features.pickel', 'rb') as f:\n",
    "    user_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029884f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_users = {}\n",
    "fn_posts = {}\n",
    "rn_users = {}\n",
    "rn_posts = {}\n",
    "\n",
    "\n",
    "for r in tqdm(df.iterrows(), total=len(df)):\n",
    "    data = r[1]\n",
    "    fn = data['fake_news_spreader']\n",
    "    user_id = data['user_id']\n",
    "    \n",
    "    for doc in data['documents']:\n",
    "        \n",
    "        # Post level\n",
    "        pl = False\n",
    "        if len(doc[4]) != 0:\n",
    "            pl = True\n",
    "            p = doc[4][0][1]\n",
    "                \n",
    "        for feat in user_features[user_id][doc[0]]:\n",
    "            \n",
    "            # User level\n",
    "            if fn == 1:\n",
    "                if feat not in fn_users:\n",
    "                    fn_users[feat] = 0\n",
    "                fn_users[feat] += user_features[user_id][doc[0]][feat]\n",
    "            else:\n",
    "                if feat not in rn_users:\n",
    "                    rn_users[feat] = 0\n",
    "                rn_users[feat] += user_features[user_id][doc[0]][feat]\n",
    "                \n",
    "            # Posts\n",
    "            if pl:\n",
    "                if p == 1:\n",
    "                    if feat not in fn_posts:\n",
    "                        fn_posts[feat] = 0\n",
    "                    fn_posts[feat] += user_features[user_id][doc[0]][feat]\n",
    "                else:\n",
    "                    if feat not in rn_posts:\n",
    "                        rn_posts[feat] = 0\n",
    "                    rn_posts[feat] += user_features[user_id][doc[0]][feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ea9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = sorted(list(set([i for i in (list(fn_users.keys()) + list(rn_users.keys())) if i != 'tokens'])), key=lambda x: rn_users[x], reverse=True)\n",
    "for i, e in enumerate(entities):\n",
    "    plt.bar(x=2*i-0.3, width=0.45, height=rn_users[e]/rn_users['tokens'], color='steelblue')\n",
    "    plt.bar(x=2*i+0.3, width=0.45, height=fn_users[e]/fn_users['tokens'], color='darkred')\n",
    "plt.xticks([i for i in range(0,2*len(entities), 2)], list(entities), rotation=90)\n",
    "plt.legend(['Real News Users', 'Fake News Users'])\n",
    "plt.ylabel('Density of Linguistic Features')\n",
    "plt.yticks([i/1000 for i in range(25, 260, 25)], ['{:2}%'.format(i/10) for i in range(25, 260, 25)])\n",
    "plt.ylim(0, 0.174)\n",
    "plt.title('Linguistic Features in Real- and Fake-News Users');\n",
    "plt.savefig('ling_feat_users.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e635a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = sorted(list(set([i for i in (list(fn_posts.keys()) + list(rn_posts.keys())) if i != 'tokens'])), key=lambda x: rn_users[x], reverse=True)\n",
    "for i, e in enumerate(entities):\n",
    "    plt.bar(x=2*i-0.3, width=0.45, height=rn_posts[e]/rn_posts['tokens'], color='steelblue')\n",
    "    plt.bar(x=2*i+0.3, width=0.45, height=fn_posts[e]/fn_posts['tokens'], color='darkred')\n",
    "plt.xticks([i for i in range(0,2*len(entities), 2)], list(entities), rotation=90)\n",
    "plt.legend(['Real News Posts', 'Fake News Posts'])\n",
    "plt.ylabel('Density of Linguistic Features')\n",
    "plt.yticks([i/1000 for i in range(25, 260, 25)], ['{:2}%'.format(i/10) for i in range(25, 260, 25)])\n",
    "plt.ylim(0, 0.199)\n",
    "plt.title('Linguistic Features in Real- and Fake-News Posts')\n",
    "plt.savefig('ling_feat_posts.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b1e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a16ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_users"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
