{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c99c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Disable all unused parts to boost the calculation\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser', 'lemmatizer', 'tok2vec', 'attribute_ruler', 'senter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefa7ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/reddit_corpus_balanced_filtered.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857276a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "user_features = {}\n",
    "for row in tqdm(df.iterrows(), desc='Evaluating Named Entities', total=len(df)):\n",
    "    data = row[1]\n",
    "    documents = data['documents']\n",
    "    user_id = data['user_id']\n",
    "    \n",
    "    user_features[user_id] = {'all': {}}\n",
    "    \n",
    "    for doc_id, text, date, sub_reddit, labels in documents:\n",
    "        \n",
    "        doc = nlp(text)\n",
    "        \n",
    "        user_features[user_id][doc_id] = {'tokens': len(doc)}\n",
    "        for token in doc:\n",
    "            if token.pos_ not in user_features[user_id][doc_id]:\n",
    "                user_features[user_id][doc_id][token.pos_] = 0\n",
    "            user_features[user_id][doc_id][token.pos_] += 1\n",
    "            \n",
    "        for pos in user_features[user_id][doc_id]:\n",
    "            if pos not in user_features[user_id]['all']:\n",
    "                user_features[user_id]['all'][pos] = 0\n",
    "            user_features[user_id]['all'][pos] += user_features[user_id][doc_id][pos]\n",
    "\n",
    "user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f66d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/linguistic_features.pickel', 'wb') as f:\n",
    "    pickle.dump(user_features, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
