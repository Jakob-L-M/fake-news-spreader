{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d30ccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8d76f1",
   "metadata": {},
   "source": [
    "## Creating data to be labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data set\n",
    "df = pd.read_pickle('../data/reddit_corpus_balanced_filtered.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading automatic labels provided by Ezzeddine\n",
    "correct_auto = set(pd.read_csv('../data/three_models_predicted_correctly.csv')['doc_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8a06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = set(pd.read_csv('../data/all_test_posts.csv')['doc_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118cf135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the number of correctly classified posts per user\n",
    "cc_factor = []\n",
    "for r in df.iterrows():\n",
    "    data = r[1]\n",
    "    user_posts = set([i[0] for i in data['documents']]) & test_set\n",
    "    \n",
    "    if len(user_posts) == 0:\n",
    "        cc_factor.append(-1)\n",
    "    else:\n",
    "        cc_factor.append(len(user_posts & correct_auto)/len(user_posts))\n",
    "df['cc'] = cc_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693c3610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop users with no post in the test set\n",
    "# Sort users by cc\n",
    "df = df[df['cc'] >= 0].sort_values(by='cc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a9f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fn top 1k users with best cc, then sort them by factual_factor (decending) and get the the top 250 \n",
    "fn_spreaders = df.sort_values(by='fn_rn_ratio', ascending=False).iloc[:500,:].sort_values(by='factual_factor',ascending=False).iloc[:250, :]\n",
    "fn_spreaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d6e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rn top 1k users with best cc, then sort them by factual_factor (ascending) and get the the top 250 \n",
    "rn_spreaders = df[df['fake_news_spreader'] == 0].iloc[:1000,:].sort_values(by='factual_factor', ascending=True).iloc[:250, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1347dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final list of 250 rn- and 250 fn-spreaders\n",
    "final_list = fn_spreaders.append(rn_spreaders)\n",
    "final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca326e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_frame = pd.DataFrame(columns=['user_id', 'post_id', 'auto_label',\n",
    "                                    'subreddit', 'text'])\n",
    "\n",
    "fact_map = {'VERY_LOW': -3, 'LOW': -2, 'MIXED': -1,\n",
    "            'MOSTLY_FACTUAL': 1, 'HIGH': 2, 'VERY_HIGH': 3}\n",
    "\n",
    "# geting one post per user\n",
    "for r in final_list.iterrows():\n",
    "    data = r[1]\n",
    "    posts = [i for i in data['documents'] if i[0] in correct_auto]\n",
    "    \n",
    "    posts = sorted(posts, key=lambda p: fact_map[p[4][0][3]], reverse=data['fake_news_spreader'] == 0)\n",
    "    \n",
    "    for p in posts[:1]:\n",
    "        label_frame = label_frame.append({'user_id':data['user_id'], 'post_id': p[0], 'auto_label': p[4][0][1],\n",
    "                            'subreddit': p[3], 'text': p[1]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf3b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb422c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_frame.to_csv('manual_labeling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dbdab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the number of correctly classified posts per user\n",
    "ncc_factor = []\n",
    "for r in df.iterrows():\n",
    "    data = r[1]\n",
    "    user_posts = set([i[0] for i in data['documents']]) & test_set\n",
    "    \n",
    "    if len(user_posts) == 0:\n",
    "        ncc_factor.append(-1)\n",
    "    else:\n",
    "        ncc_factor.append(len(user_posts - correct_auto)/len(user_posts))\n",
    "df['ncc'] = ncc_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac2ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc = df[df['ncc'] > 0].sort_values(by='ncc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aebfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_label_frame = pd.DataFrame(columns=['user_id', 'post_id', 'auto_label',\n",
    "                                    'subreddit', 'text'])\n",
    "\n",
    "fact_map = {'VERY_LOW': -3, 'LOW': -2, 'MIXED': -1,\n",
    "            'MOSTLY_FACTUAL': 1, 'HIGH': 2, 'VERY_HIGH': 3}\n",
    "\n",
    "# geting one post per user\n",
    "for r in ncc.iterrows():\n",
    "    \n",
    "    if len(nc_label_frame) >= 500:\n",
    "        break\n",
    "    \n",
    "    data = r[1]\n",
    "    posts = [i for i in data['documents'] if (i[0] in test_set and i[0] not in correct_auto)]\n",
    "    \n",
    "    for p in posts[:1]:\n",
    "        nc_label_frame = nc_label_frame.append({'user_id':data['user_id'], 'post_id': p[0], 'auto_label': int(not bool(p[4][0][1])),\n",
    "                            'subreddit': p[3], 'text': p[1]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64a5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_label_frame.to_csv('ncc_manual_labeling.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a7b3a",
   "metadata": {},
   "source": [
    "## Statistical look at the manualy labeld posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e8c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = pd.read_csv('cc_manual_labeling.csv', sep=';', encoding= 'unicode_escape')\n",
    "lab = lab[(lab['manual_label'] == '0')| (lab['manual_label'] == '1')]\n",
    "lab['manual_label'] = np.array(lab['manual_label'], dtype=np.int8)\n",
    "\n",
    "changes = lab[lab['auto_label'] != lab['manual_label']]\n",
    "\n",
    "df = pd.read_pickle('../data/reddit_corpus_balanced_filtered.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb525a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_ids = []\n",
    "for row in changes.iterrows():\n",
    "    data = row[1]\n",
    "    amounts = df[df['user_id'] == data['user_id']]['amounts'].values[0]\n",
    "    \n",
    "    manual_label = data['manual_label']\n",
    "    \n",
    "    if manual_label == 1 and amounts[1] == 0:\n",
    "        c_ids.append(data['user_id'])\n",
    "        print('change to fn:', data['user_id'])\n",
    "    elif manual_label == 0 and amounts[1] == 1:\n",
    "        c_ids.append(data['user_id'])\n",
    "        print('change to rn:', data['user_id'])\n",
    "        \n",
    "df[[u_id in c_ids for u_id in df['user_id']]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
